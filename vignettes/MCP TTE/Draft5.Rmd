---
title: "Time-to-Event Data MCP-Mod"
output: rmarkdown::html_vignette
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rmarkdown.html_vignette.check_title = FALSE
```

```{r, echo=F, results='hide', message=FALSE}
library(`DoseFinding`, lib.loc = "~/RStudio/packages")
library(truncnorm)
library(dplyr)
library(survival)
library(ggsurvfit)
library(ggplot2)
```

In this vignette we illustrate how to use the `DoseFinding` package with survival endpoints.

## Background and Data Set
Assume a dose-finding study is planned for an hypothetical investigational treatment. The endpoint of interest is time to a certain event. The treatment is tested with doses $0$ (placebo), $0.2$, $0.5$ and $1$, with a ratio of $2:1:1:2$. It is assumed that the yearly hazard rate for the placebo group is $\lambda_0 = 0.6$ and that the hazard ratio for the treatment effect on the highest dose, here $\text{HR} = 0.5$, is provided.\
For calculations we need $\lambda_1$, the hazard rate for the treatment group on dose $1$. This can be derived by multiplication:
$$
\begin{aligned}
\text{HR} = \frac{\lambda_1}{\lambda_0} 
\Leftrightarrow \text{HR} \cdot \lambda_0 = \lambda_1 
\end{aligned}
$$
In case median survival time $T_{0.5}$ is given, this can be transformed to a hazard rate using:
$$
\begin{aligned}
\lambda = \frac{\ln(2)}{T_{0.5}}
\end{aligned}
$$

This can be derived from the definition of the survival function:
$$
\begin{aligned}
S(T_{0.5}) &= 0.5 \\
\Leftrightarrow \exp(-\lambda T_{0.5}) &= 0.5\\
\Leftrightarrow \ln(\exp(-\lambda T_{0.5})) &= \ln(0.5)\\
\Leftrightarrow -\lambda T_{0.5} &= \ln(0.5)\\
\Leftrightarrow \lambda T_{0.5} &= - \ln(0.5)\\
\Leftrightarrow \lambda T_{0.5} &= \ln(2)\\
\Leftrightarrow T_{0.5} &= \frac{\ln(2)}{\lambda}\\
\Leftrightarrow T_{0.5} \cdot \lambda &= \ln(2)\\
\Leftrightarrow \lambda &= \frac{\ln(2)}{T_{0.5}}\\
\end{aligned}
$$

We define some parameters for example data in the setting just described:
```{r}
lambda0 <- 0.6 # yearly hazard rate for Control/Placebo group
HR_treat <- 0.5 # hazard ratio for treatment effect on the highest dose
lambda3 <- lambda0 * HR_treat #  hazard rate for Treatment group on highest dose
doses <- c(0, 0.2, 0.5, 1) # placebo or group and 3 treatment groups
ratio <- c(1, 0.5, 0.5, 1)  # the first number is always 1
ngroup <- length(doses) 
n <- 100 # number of patients
etotal <- 50 # predefined total number of events
```


## Candidate models
We will use the following candidate set of dose response models for the mean response: An $\text{E}_{max}$ model, a sigmoidal $\text{E}_{max}$ model, a quadratic, a n exponential and a linear model. For the $\text{E}_{max}$ model, $\text{ED}_{50}$ (the dose at
which half of the maximum effect is reached) of $1$ will be used as "guesstimates". For the
sigmoidal $\text{E}_{max}$, $\text{ED}_{50}$ will be $10$ with hill parameter $4$.\
In survival context, it is important to remember that `direction` is `decreasing`. Alternatively, one can specify a negative `maxEff` argument.\
`placEff` is expecting the log hazard rate of the placebo arm, so $\log\left(\lambda_0\right)$.\
`maxEff` is the maximum effect size within the dose-range. It is expecting the difference between the response at the highest dose and `placEff`, the log(HR):

$$
\begin{aligned}
\text{HR} = \frac{\lambda_1}{\lambda_0} 
\Leftrightarrow \log(\text{HR}) = \log\left(\lambda_1\right) - \log\left(\lambda_0\right)
\end{aligned}
$$
We use log hazard rates here because dose-response models in the `DoseFinding` package assume additive effects when specifying responses.
```{r, fig.width = 9, out.width = '100%'}
mods <- Mods(
  emax = c(1),
  sigEmax = rbind(c(10, 4)),
  quadratic = -0.5,
  exponential = 0.7,
  linear = NULL,
  doses = doses,
  direction = c("decreasing"), # decreasing in survival contexts
  placEff = log(lambda0), # log hazard rate for placebo arm
  maxEff = log(lambda3) - log(lambda0) 
  # difference between the response at the highest dose and placEff
)

plotMods(mods, superpose = T, ylab = 'log (hazard rates)')
```


```{r}
#' Extracts the log hazard rates for all doses per defined model
#'
#' @param mods  Set of dose-response models; an object of class \samp{Mods}, 
#' see [Mods()] for details
#'
#' @return matrix y with all log hazard rates per dose level and per model
#'
#' @export
log_hazard_rates <- function(mods) {
  y0 <- getResp(mods, doses = attr(mods, "doses"))
  y <- y0[1:dim(y0)[1],]
  return(y)
}
#' @examples
#' ## define 2 models, including the doses, direction decreasing in survival 
#' contexts, 
#' placEff is log hazard rate for placebo arm 
#' and # difference between the response at the highest dose and placEff
#' mods <- Mods(
#'  emax = c(1),
#'  linear = NULL,
#'  doses = c(0, 1, 1.5, 3),
#'  direction = c("decreasing"),
#'  placEff = log(0.6), 
#'  maxEff = log(0.3) - log(0.6) # difference between the response at the 
#'  highest dose and placEff
#'
#' log_hazard_rates(mods) log hazard rates
#' exp(log_hazard_rates(mods)) # hazard rates
```

## Data generation
```{r}
#' Data generation for Survival Data following exponential or Weibull distribution
#' 
#' Simulate survival data using an exponential or Weibull distribution with the 
#' true hazard rates from one model of \samp{mods}, 
#' with event driven censoring after \samp{etotal} events happen and with 
#' staggered study entry.
#' To implement the staggered study entry, an entry time for each patient is 
#' computed and added to their event time. Then the event time is given in 
#' calendar time. Then the data gets censored after the predefined number of 
#' events and event time is again reduced by entry time to get the event time 
#' in study time for the output
#'
#' @param mods Set of dose-response models; an object of class \samp{Mods}, 
#' see [Mods()] for details
#' @param model wither Name or Number of the model from \samp{mods} of which 
#' the hazards should be taken from
#' @param ratio Vector of Sample Size allocation ratio, according to doses used 
#' in \samp{mods}, first number must be 1
#' @param n sample size
#' @param etotal number of events after which event driven censoring is 
#' implemented, time cutoff when etotal of event being observed
#' @param staggered boolean variable, if true, study entry should be staggered
#' @param distribution character, either "exponential" or "weibull"
#' @param shape shape needed if "weibull" is chosen, if shape == 1, then equal 
#' to exponential function
#' @param scale scale needed if "weibull" is chosen
#'
#' @return list of 
#' - the data set including the variables \samp{group}, referring to the doses 
#' (0 for placebo), \samp{hazard}, \samp{time} which is the event time and 
#' \samp{status} which is 0 if censored and 1 if event was observed
#' - plot showing the distribution of time to event
#' @references RÃ¼hl 2022 (for staggered study entry and event times using 
#' Weibull distribution)
#' @export
simulate_surv_data <- function(mods,
                               model,
                               ratio,
                               n,
                               etotal,
                               staggered = F,
                               distribution = c("exponential", "weibull"),
                               shape = 2,
                               scale = 3) {
  set.seed(2026)
  doses <- attr(mods, "doses")
  y <- log_hazard_rates(mods)
  mean_resp <- sample(y[, model], n, replace = T, prob = ratio) 
  # mean resp are log hazard rates
  lambda0 <- exp(attr(mods, "placEff"))
  
  distribution <- match.arg(distribution)
  if (staggered == T) {
    if (distribution == "exponential") {
      entry <- runif(n, 0, qexp(etotal / n, lambda0))
      event <- entry + rexp(n, exp(mean_resp)) # calendar time, hazard rates
      text <- "Staggered Study Entry and Exponential Distribution of Event 
      Times"
    } else if (distribution == "weibull") {
      entry <- runif(n, 0, qweibull(etotal / n, shape, scale))
      event <-
        entry + c(rweibull(n, shape, (scale / (
          exp(mean_resp) / lambda0
        )) ^ (1 / shape)))
      text <- "Staggered Study Entry and Weibull Distribution of Event Times"
    }
  } else if (staggered == F) {
    entry <- rep(0, n)
    if (distribution == "exponential") {
      event <- rexp(n, exp(mean_resp))
      text <- "NO Staggered Study Entry and Exponential Distribution of Event 
      Times"
    } else if (distribution == "weibull") {
      event <-
        c(rweibull(n, shape, (scale / (
          exp(mean_resp) / lambda0
        )) ^ (1 / shape)))
      text <- "NO Staggered Study Entry and Weibull Distribution of Event Times"
    }
  }
  t_max_event <- sort(event)[etotal]
  status <- (event <= t_max_event)
  censoring <- pmin(event, t_max_event)
  study_time <- censoring - entry # study time
  
  data <- data.frame(
    group = names(mean_resp),
    hazard = mean_resp,
    time = study_time,
    status = as.numeric(status)
  )
  data$group <- factor(data$group, levels = as.character(doses))
  
  plot <- ggplot(data, aes(x = time)) +
    geom_histogram(bins = floor(max(data$time)) * 4,
                   color = "black",
                   fill = "white") +
    ggtitle(paste("Distribution of Time to Event (in Study Time)\n ", text)) +
    theme(plot.title = element_text(hjust = 0.5))
    
  return(list(data, plot))
}
#'
#' @examples
#' generate some survival data set that follows an exponential distributions 
#' with hazards from the Emax model
#' simulation <- simulate_surv_data(
#'    mods = mods,
#'    model = 1,
#'    ratio = c(1, 0.5, 0.5, 1),
#'    n = 100,
#'    etotal = 50,
#'    staggered = T,
#'    distribution = "exponential")
#' (data <- simulation[[1]])
#' (data_plot <- simulation[[2]])
```

```{r}
simulation <- simulate_surv_data(
    mods,
    model = 1,
    ratio,
    n = 100,
    etotal = 80,
    staggered = F,
    distribution = "weib",
    shape = 2, 
    scale = 5)

data <- simulation[[1]]
data_plot <- simulation[[2]]
```


```{r, fig.width = 5, out.width = '90%', echo=FALSE}
model <- 1
ratio <- c(1, 0.2, 0.5, 1)
n <- 100
etotal <- 90
shape <- 2 
scale <- 5

(data_plot_F_exp <- simulate_surv_data(mods, model, ratio, n, etotal, shape, 
                                       scale, staggered = F, 
                                       distribution = "exp")[[2]])
(data_plot_F_weib <- simulate_surv_data(mods, model, ratio, n, etotal, shape, 
                                        scale, staggered = F, 
                                        distribution = "weib")[[2]])
(data_plot_T_exp <- simulate_surv_data(mods, model, ratio, n, etotal, shape, 
                                       scale, staggered = T, 
                                       distribution = "exp")[[2]])
(data_plot_T_weib <- simulate_surv_data(mods, model, ratio, n, etotal, shape, 
                                        scale, staggered = T, 
                                        distribution = "weib")[[2]])

mean(simulate_surv_data(mods, model, ratio, n, etotal, shape, scale, 
                        staggered = F, distribution = "exp")[[1]] $ time)
mean(simulate_surv_data(mods, model, ratio, n, etotal, shape, scale, 
                        staggered = F, distribution = "weib")[[1]] $ time)
mean(simulate_surv_data(mods, model, ratio, n, etotal, shape, scale, 
                        staggered = T, distribution = "exp")[[1]] $ time)
mean(simulate_surv_data(mods, model, ratio, n, etotal, shape, scale, 
                        staggered = T, distribution = "weib")[[1]] $ time)
```

Look at the survival data with a Kaplan-Meier plot:
```{r, fig.width = 5, out.width = '100%'}
survfit2(Surv(time, status) ~ group, data = data) %>%
  ggsurvfit() +
  labs(x = "Years",
       y = "Survival Probability",
       title = "Kaplan-Meier Estimator by Dose",
       ) +
  theme(plot.title = element_text(hjust = 0.5)) 
```

## Cox's Semiparametric Regression Model
The Cox's semiparametric regression model expresses the hazard rate like this
$$
\begin{aligned}
\lambda \left(t|x_1,\ldots, x_p\right) = \lambda_0\left(t\right)\exp\left(\beta_1x_1+ \ldots \beta_px_p\right)
\end{aligned}
$$

with\
$\lambda_0\left(t\right)$ baseline hazard,\
$x_1,\ldots, x_p$ covariates,\
$\beta_1,\ldots\beta_p$ regression coefficients (effects) of the covariates\
$\exp\left(\beta_1x_1+ \ldots \beta_px_p\right)$ and hazard ratio\
(Book ABG)\
here: $x$ refers to the doses, so\
$$
\begin{aligned}
\lambda \left(t|\text{doses}\right) &= \lambda_0\left(t\right)\exp\left(\beta_1 \cdot 0\, + \beta_2 \cdot 0.2\, + \beta_3 \cdot 0.5\, + \beta_4 \cdot 1\,\right) \\
\end{aligned}
$$
Run Cox PH Model:\
Fit the Cox Proportional Hazards model to the survival data. Evaluate whether the treatment has a significant effect on survival:
```{r}
cox <- coxph(Surv(time, status) ~ group, data = data)
summary(cox)
```

Coefficients are estimates. Contain the estimated log hazard ratios for each dose group relative to the reference group, typically placebo: 
```{r}
coef <- cox$coef
```

Variance-covariance matrix of the estimated coefficients from the Cox Proportional Hazards Model
```{r}
cov <- cox$var 
```

# Analysis
The Cox's regression model provides the estimated coefficients and their estimated covariance matrix. This is used for some analyses.\
NOW: Everything placAdj = TRUE !!!

## Multiple Contrast Test
How well do the different potential dose-response models fit the data compared to the null hypothesis $H_0$: "No dose-response relationship"?\
Evaluate dose-response relationships using the MCPMod approach. Tests for significant differences across doses
```{r}
mct <-
  MCTtest(
    dose = doses[-1], # placebo adjusted
    resp = coef,
    S = cov,
    models = mods,
    type = 'general',
    alternative = "one.sided",
    placAdj = TRUE # placebo-adjusted estimates are specified in ââ respâ â
  )
mct
```

The first table shows the same matrix as `optContr` containing optimal contrasts for candidate shapes. It shows how much weight each dose contributes to the test for each hypothesized model.\
(like book p.220 Table 12.3)\

The second table contains the result of the contrast test. It shows how similar or related the estimated contrasts for each model are.\
High correlations (near 1) between models (e.g., emax1 and emax2) suggest these models produce similar dose-response patterns.\
(like book p.220 Table 12.4 or p.222 Table 12.6).\

The third table gives the $t$-statistics and adjusted $p$-values for each model.\
It shows how strong the evidence for the corresponding model is.\
A higher $t$-statistic suggests better compatibility between the model and the observed data.\
Small adjusted $p$-values ($< 0.05$) indicate strong evidence for the model fitting better than the null hypothesis ("no dose-response relationship"). Here, all adjusted $p$-values are small, so this gives a strong evidence for the existence of a dose-response effect.\

The model with smallest $p$-value and highest $t$-statistic is considered the best model, with the strongest statistical evidence for detecting the dose-response pattern. Here, this would be emax2 which makes sense as this is the distribution used for data generation.

## Find the best model (see book p. 219)
Plot of estimated dose-response curve (book p. 220)\
Like plot in book p.221, Fig 12.2

```{r, fig.width = 6.9, out.width = '100%'}
fitEmax <- fitMod(
  dose = doses[-1],
  resp = coef,
  S = cov,
  model = 'emax',
  type = 'general',
  placAdj = TRUE
)
plot(fitEmax, title = "TITEL")
aic_emax <- gAIC(fitEmax)

fitSigEmax <- fitMod(
  dose = doses[-1],
  resp = coef,
  S = cov,
  model = 'sigEmax',
  type = 'general',
  placAdj = TRUE
)

plot(fitSigEmax)
aic_sigemax <- gAIC(fitSigEmax) 

ifelse(aic_emax <= aic_sigemax, 
       paste('Emax model fits better than SigEmax regarding the gAIC values of 
             the models.'),
       paste('SigEmax model fits better than Emax regarding the gAIC values of 
             the models.'))
```
Preferred model is the one with the minimum AIC value.\

## Find the best dose (see book p. 220)
Here, decreasing response is beneficial (as before).\
Find a dose that achieves a certain percentage of the full effect size over placebo, usually $0.9$ as it is close to the plateau.
```{r}
percentage_dose_emax <- ED(fitEmax, p = 0.9, direction = 'decreasing')
percentage_dose_emax

percentage_dose_sigemax <- ED(fitSigEmax, p = 0.9, direction = 'decreasing')
percentage_dose_sigemax
```


Predict the effect of more doses, e.g. $0.3$ and $1.5$ (book p. 220)
```{r}
pred_emax <- predict(fitEmax, doseSeq = c(0.3, 1.5), 
                     predType = 'effect-curve', se.fit = T)
pred_emax

pred_sigemax <- predict(fitSigEmax, doseSeq = c(0.3, 1), 
                        predType = 'effect-curve', se.fit = T)
pred_sigemax 
```


# Power and sample size
Contrasts help assess whether a dose-response relationship exists by comparing the effects of different doses in the trial.\
Use $w = 1$ if homoscedastic residuals with equal group sizes, which is not the case here.\
```{r, fig.width = 6.9, out.width = '100%'}
contMat <- optContr(mods, w = ratio) 
summary(contMat) # cols add up to ~0 
plotContr(contMat) # display contrasts using ggplot2
```

For the functions `sampSizeMCT` and `powN` there is `sigma` needed which we have to derive like in (deng2019power) for survival settings.\
They derived the covariance matrix $S$ of $\hat{\beta}$:
$$
\begin{aligned}
S \approx D^{-1}
\begin{pmatrix}{}
p_0^{-1} + p_1^{-1} & p_0^{-1} & \ldots & p_0^{-1} \\
p_0^{-1} & p_0^{-1} + p_2^{-1} & \ldots & p_0^{-1} \\
\vdots  & \vdots  & \vdots  & \vdots\\
p_0^{-1} & p_0^{-1} & \ldots  & p_0^{-1} + p_K^{-1} \\
\end{pmatrix}
\end{aligned}
$$
with 
$$
\begin{aligned}
p_k = \frac{\frac{n_k}{n_0}\exp(\beta_k)}{1 + \sum_{i = 1}^{K}\frac{n_i}{n_0}\exp(\beta_i)},
\end{aligned}
$$
$n_k$ the number of patients in dose group $k$ for $k = 0, 1, \ldots, K$, $k = 0$ placebo,\
$n = n_0 + n_1 + \ldots + n_k$,\
$\beta_0 = 0$\

Under $H_0$, $S$, say, $S_0$, then has the following structure:\
$$
\begin{aligned}
S_0 \approx \frac{n}{D}
\begin{pmatrix}{}
n_0^{-1} + n_1^{-1} & n_0^{-1} & \ldots & n_0^{-1} \\
n_0^{-1} & n_0^{-1} + n_2^{-1} & \ldots & n_0^{-1} \\
\vdots  & \vdots  & \vdots  & \vdots\\
n_0^{-1} & n_0^{-1} & \ldots  & n_0^{-1} + n_K^{-1} \\
\end{pmatrix}
\end{aligned}
$$

with $D =$ total number of events (before named `etotal`)\

(see everything paper deng2019power)
# here: for all models
```{r}
#' Compute the Covariance matrices S and S0
#' 
#' Forpower and sample size calculations in MCP-Mod, knowledge of the cavaraince 
#' matrix for the estimators of the placebo-adjusted mean response among the
#' dose groups is needed. In survival settings, this can not be derived using 
#' standard software.
#' Deng et al. derived an explicit form of the covariance matrix for the 
#' estimators of the log hazard ratios. Those are needed to evaluate the power 
#' analytically.
#' 
#'
#' @param mods Set of dose-response models; an object of class \samp{Mods}, 
#' see [Mods()] for details
#' @param ratio Vector of Sample Size allocation ratio, according to doses used 
#' in \samp{mods}, first number must be 1
#' @param etotal number of events after which event driven censoring is 
#' implemented, time cutoff when etotal of event being observed 
#'
#' @return
#' - S, the covariance matrix adapted to the survival setting, to calculate the 
#' optimal contrast coefficients and power
#' - S0, the covariance matrix adapted to the survival setting under H0, to 
#' determine the critical value 
#' @references Deng 2019
#' @export
S_and_S0 <- function(mods, ratio, etotal) {
  y <- log_hazard_rates(mods)
  # second column of beta / for second model here
  lambda0 <- attr(mods, "placEff")
  beta <- y - lambda0 # placebo adjusted log hazard rates
  nshape <- ncol(beta)
  ngroup <- nrow(beta) 
  # 0.5 * beta = intermediate value between 0 and beta:
  # See paper deng2019power (appendix last sentence)
  p0 = 1 / apply(exp(0.5 * beta) * ratio, 2, sum) # sum of columns
  pk = (exp(0.5 * beta) * ratio) %*% diag(p0)
  
  # S matrix
  # Use S for calculating contrast and power
  # Dimensions are reduced by 1 because the placebo group is excluded
  # fill with 0s, 3-dimensional as given in c(...)
  S <- array(0, c(ngroup - 1, ngroup - 1, nshape)) 
  for (i in 1:nshape) {
    S[, , i] <- 1 / p0[i]
    diag(S[, , i]) <- 1 / pk[-1, i] + 1 / p0[i]
  }
  S = S / etotal
  
  # S0 matrix
  # use S0 to derive critical value
  S0 <- diag(sum(ratio) + sum(ratio) / ratio[-1])
  S0[upper.tri(S0)] <- S0[lower.tri(S0)] <- sum(ratio)
  S0 <- S0 / etotal
  
  return(list(S = S, S0 = S0))
}

#' @examples
#' S <- S_and_S0(mods = mods, ratio = c(1, 0.5, 0.5, 1), etotal = 50)$S
#' S0 <- S_and_S0(mods = mods, ratio = c(1, 0.5, 0.5, 1), etotal = 50)$S0
```


Power estimation using the calculated S and S0:
```{r}
S <- S_and_S0(mods, ratio, etotal)$S
S0 <- S_and_S0(mods, ratio, etotal)$S0
alpha <- 0.05

contMat <- optContr(mods, doses = doses[-1], S = S[,, 1], placAdj = T)[[1]]
```

```{r}
#' Extract information from the models defined
#' 
#' Helper function to derive characteristics from the models defined with  
#' \samp{Mods}.
#' Those are needed in following functions.
#' The functions \samp{log_hazard_rates} and \samp{S_andS0} defined above are 
#' used here.
#'
#' @param mods Set of dose-response models; an object of class \samp{Mods}, 
#' see [Mods()] for details
#' @param ratio Vector of Sample Size allocation ratio, according to doses used 
#' in \samp{mods}, first number must be 1
#' @param etotal number of events after which event driven censoring is 
#' implemented, time cutoff when etotal of event being observed 
#'
#' @return
#' - matrix y: all log hazard rates per dose level and per model
#' - lambda 0: yearly hazard rate for Control/Placebo group
#' - nshape: number of models defined 
#' - doses: vector of the doses, starting with 0 for the placebo group
#' - ngroup: number of dose groups
#' - S: covariance matrix for the survival setting
#' - S0: covariance matrix under H0 for the survival setting
#' - contMat: contrast matrix for all models and all dose groups computed using 
#' the \samp{optContr} function from the \samp{DoseFinding} package
#' @export
model_info <- function(mods, ratio, etotal) {
  y <- log_hazard_rates(mods)
  lambda0 <- exp(attr(mods, "placEff"))
  nshape <- dim(y)[2]
  doses <- attr(mods, "doses")
  ngroup <- length(doses)
  
  # S and S0
  sim <- S_and_S0(mods, ratio, etotal)
  S <- sim$S # one for each model
  S0 <- sim$S0 # one, independent of the model specifications
  
  return(list(y = y, lambda0 = lambda0, nshape = nshape, doses = doses, 
              ngroup = ngroup, S = S, S0 = S0))
}
#' @examples
#' model_information <- model_info(mods = mods, ratio = c(1, 0.5, 0.5, 1), 
#' etotal = 50)
```

```{r}
model_information <- model_info(mods, ratio, etotal)
```

```{r}
#' Compute power
#'
#' \samp{powMCT_TTE} is a modification of \samp{powMCT1} of Deng 2019 which is 
#' a modification of the \samp{pow_MCT} function from the \samp{DoseFinding}
#' package.
#' Here, the function computes S and S0 using the subfunction \samp{S_and_S0}. 
#' They are used as covariance matrix for the estimates.
#' This happens using S0 for the \samp{critVal} function from the 
#' \samp{DoseFinding} package. With the critical value and with S, the power is 
#' then 
#' computed given a certain amount of events (\samp{etotal}) using the
#' \samp{powCalc} funciton from the \samp{DoseFinding} package.
#' \samp{cov2cor()} is used to scale a covariance matrix by its diagonal to 
#' become the correlation matrix
#' The test is one sided using the significance level provided.
#' The calculations are based on the assumption of placebo-adjusted estimates, 
#' the contrast matrix is
#' produced on placebo-adjusted scale
#'
#' @param mods Set of dose-response models; an object of class \samp{Mods}, 
#' see [Mods()] for details, defining the mean vectors
#' under which the power should be calculated
#' @param alpha Significance level to use
#' @param ratio Vector of Sample Size allocation ratio, according to doses used 
#' in \samp{mods}, first number must be 1
#' @param etotal number of events after which event driven censoring is 
#' implemented, time cutoff when etotal of event being observed 
#'
#' @return Numeric vector containing the calculated power values under each 
#' candidate model as well as the average
#' @references Pinheiro, J. C., Bornkamp, B., and Bretz, F. (2006). Design and
#' analysis of dose finding studies combining multiple comparisons and modeling
#' procedures, *Journal of Biopharmaceutical Statistics*, **16**,
#' Deng 2019
#' @export
powMCT_TTE <-
  function(mods,
           alpha,
           ratio,
           etotal) {
    set.seed(123)
    model_information <- model_info(mods, ratio, etotal)
    doses <- model_information$doses
    nshape <- model_information$nshape
    S <- model_information$S
    S0 <- model_information$S0
    mcpmod_power <- rep(0, nshape)
    contMat <- optContr(mods,
             doses = doses[-1],
             S = S[, , 1],
             placAdj = T)[[1]]
    contMat <- contMat[, 1, drop = F]
    
  if (nshape > 1) {
      for (i in 2:nshape) {
        contrast <-
          optContr(mods,
                   doses = doses[-1],
                   S = S[, , i],
                   placAdj = T)[[1]]
        contrast <- contrast[, i, drop = F]
        contMat <- cbind(contMat, contrast)
      }
    }
    for (j in 1:nshape) {
      muMat <- getResp(mods)[,j, drop = FALSE]  
      # responses are expressed relative to the placebo.
      muMat <- sweep(muMat, 2, muMat[1, ], "-") 
      muMat <- muMat[-1, , drop = FALSE]
      deltaMat <- t(contMat) %*% muMat 
      covMat <- t(contMat) %*% S[, , j] %*% contMat
      den <- sqrt(diag(covMat))
      deltaMat <- deltaMat / den
      corMat <- cov2cor(covMat)
      covMat0 <- t(contMat) %*% S0 %*% contMat 
      corMat0 <- cov2cor(covMat0) 
      critV <- critVal(
        corMat0,
        alpha,
        df = 0,
        alternative = "one.sided",
        control = mvtnorm.control()
      ) 
      pow <- DoseFinding:::powCalc(
        alternative = "one.sided",
        critV,
        df = 0,
        corMat,
        deltaMat,
        control = mvtnorm.control()
      )
      mcpmod_power[j] <- pow
    }
    power_av <- round(mean(mcpmod_power), 4)
    round(mcpmod_power, 5)
    power_table <- data.frame(model = names(deltaMat[,1]), power = mcpmod_power)
    # print(list(pow = pow, critV=critV, df=df, corMat=corMat, corMat0=corMat0, 
    # covMat=covMat, covMat0=covMat0, deltaMat=deltaMat))
    return(list(power_table = power_table, power_av = power_av))
  }
#' @examples
#' power_calc <- powMCT_TTE(mods = mods, alpha = 0.05, 
#' ratio = c(1, 0.5, 0.5, 1), etotal = 30)
#' pow_sep <- power_calc$power_table 
#' pow_av <- power_calc$power_av 
#' 
```
The function provides the power for each model separately (pow_sep) as well as the average power over all models (pow_av):
```{r}
power_calc <- powMCT_TTE(mods, alpha, ratio, etotal = 30)
pow_sep <- power_calc$power_table # power under each candidate model
pow_av <- power_calc$power_av # average power

pow_sep
pow_av
```


```{r}
#' compute the number of total events needed given a desired power
#' 
#' \samp{no_events_given_pow function} computes the number of total events 
#' needed given a desired power (\samp{des_pow}, in percent) using 
#' the \samp{powMCT_TTE} function. It also provides a graph showing the average 
#' power under the given models until the desired power is reached. 
#' Starting at one event, the power is calculated. as long as the desired power 
#' is not reached yet, the number of events gets raised by $1$. When the desired 
#' power is reached, the loop ends.
#'
#' @param mods Set of dose-response models; an object of class \samp{Mods}, 
#' see [Mods()] for details
#' @param alpha Significance level to use
#' @param ratio Vector of Sample Size allocation ratio, according to doses used 
#' in \samp{mods}, first number must be 1
#' @param des_pow desired power one wants to achieve
#'
#' @return
#' - number of total events needed given the desired power 
#' - graph showing the average power under the given models until the desired 
#' power is reached
#' @export
no_events_given_pow <- function(mods, alpha, ratio, des_pow){
  pow <- 0
  etotal_col <- c(0)
  pow_col <- c(0)
  
  for (i in 1:1000){
    etotal <- i
    pow <- powMCT_TTE(mods, alpha, ratio, etotal)$power_av
    etotal_col[i] <- i
    pow_col[i] <- pow
    if(pow >= des_pow) break
  }
  dat <- data.frame(etotal_col, pow_col)
  graf <- ggplot(data = dat, aes(x = etotal_col, y = pow_col, group = 1)) +
  geom_line()+
  geom_point() +
    xlab("Total Number of Events") + 
    ylab("Power") +
    geom_hline(yintercept = des_pow, linetype="dashed") +
    annotate("text", x = etotal / 6, y = des_pow - 0.02, 
             label = "Desired Power") +
    ggtitle("Total Number of Events Needed to Reach the Desired Power")
  
  return(list(etotal = etotal, graf = graf))
}
#' @examples
#' test <- no_events_given_pow(mods = mods, alpha = 0.25, 
#' ratio = c(1, 0.5, 0.5, 1), des_pow = 0.8)
#' test$etotal
#' test$graf
```


```{r, fig.width = 6.9, out.width = '100%'}
des_pow <- 0.8
test <- no_events_given_pow(mods, alpha, ratio, des_pow)
test$etotal
test$graf
```

```{r}
#' calculate the number of events given a certain sample size
#' 
#' The \samp{no_events_given_samplesize} function calculates the number of 
#' events given a certain sample size.
#' Therefore, the formula from Deng 2019 which is derived from equation 26 in 
#' Lachin 1981 is used.
#' It is assumed that patients are recruited uniformly over the time period 
#' $[0, \text{end_rec}]$ and that the survival time for group $k$ follows 
#' the exponential distribution with hazard $\lambda_k$.
#' One model has to be chosen to compute the needed $\lambda_k$'s.
#'
#' @param ratio Vector of Sample Size allocation ratio, according to doses used 
#' in \samp{mods}, first number must be 1
#' @param mods Set of dose-response models; an object of class \samp{Mods}, 
#' see [Mods()] for details
#' @param end_rec end of recruitment period in years
#' @param end_stu endpoint of the study in years
#' @param model wither Name or Number of the model from \samp{mods} of which the 
#' hazards should be taken from
#' @param n sample size
#'
#' @return
#' - total number of events 
#' - vector with the number of events per group
#' @references Deng 2019, Lachin 1981
#' @export
no_events_given_samplesize <- function(ratio, mods, end_rec, end_stu, model, n){
  y <- log_hazard_rates(mods)
  ngroup <- length(ratio)
  lambda <- exp(y)[,model]
  rat <- ratio/sum(ratio)
  D <- rep(0, ngroup)
  for (i in 1:ngroup){
    D[i] <- (n * rat[i]) * (1 - ((exp(-lambda[i] * (end_stu - end_rec)) - 
                                    exp(-lambda[i] * end_stu)) / 
                                   (lambda[i] * end_rec))) 
  }
  return(list(e_vec = D, etotal_samp = sum(D)))
}
#' @examples
#' no_events_given_samplesize(ratio = c(1, 0.5, 0.5, 1), 
#' mods = mods, end_rec = 1, end_stu = 3, model = 2, n = 100) 
```

```{r}
no_events_given_samplesize(ratio, mods, end_rec = 1, end_stu = 3, model = 2, 
                           n = 100) 
```

```{r}
#' calculate the total sample size needed to achieve a certain power
#'
#' \samp{samplesize_given_power} calculates the total sample size needed to 
#' achieve a certain power.
#' Starting with a minimum number of patients (\samp{n_mind}) it computes the 
#' number of events happening using the sample_size function.
#' With that number of events (\samp{etotal_int}) it computes the power this 
#' study would have (\samp{pow}) using the \samp{powMCT_TTE} function.
#' The function stops when the desired power (\samp{des_pow}) is reached and 
#' provides a plot showing the power for various sample sizes.
#' Here, the \samp{no_events_given_samplesize} is used to compute the number of 
#' events.

#' @param mods Set of dose-response models; an object of class \samp{Mods}, 
#' see [Mods()] for details
#' @param alpha Significance level to use
#' @param ratio Vector of Sample Size allocation ratio, according to doses used 
#' in \samp{mods}, first number must be 1
#' @param des_pow desired power one wants to achieve
#' @param end_rec end of recruitment period in years
#' @param end_stu endpoint of the study in years
#' @param model wither Name or Number of the model from \samp{mods} of which the 
#' hazards should be taken from
#' @param n_mind minimum number of patients with which the loop starts, should 
#' not be chosen too small, so meaningful allocaition can be computed and to 
#' reduce running time
#'
#' @return
#' - number of total sample size needed given the desired power 
#' - graph showing the average power under the given models until the desired 
#' power is reached
#' - text explaining the output
#' @references Deng 2019, Lachin 1981
#' @export
samplesize_given_power <-
  function(mods,
           alpha,
           ratio,
           des_pow,
           end_rec,
           end_stu,
           model,
           n_mind = 20) {
    
    pow <- 0
    n_col <- c(0)
    pow_col <- c(0)
    
    for (i in (n_mind:1000)) {
      n <- i
      etotal_int <-
        floor(no_events_given_samplesize(ratio, mods, end_rec, end_stu, model,
                          n = n)$etotal_samp)
      pow <-
        powMCT_TTE(mods, alpha, ratio, etotal = etotal_int)$power_av
      n_col[i - n_mind] <- i
      pow_col[i - n_mind] <- pow
      if (pow >= des_pow)
        break
    }
    
    dat <- data.frame(n_col, pow_col)
    graf <-
      ggplot(data = dat, aes(x = n_col, y = pow_col, group = 1)) +
      geom_line() +
      geom_point() +
      xlab("Total Sample Size") +
      ylab("Power") +
      geom_hline(yintercept = des_pow, linetype = "dashed")  +
      annotate("text", x = etotal / 2, y = des_pow - 0.02, 
             label = "Desired Power") +
      ggtitle("Total Sample Size Needed to Reach the Desired Power")
    
    text <- paste("To reach the desired power of", des_pow * 100, "%, ", n, 
                  "patients are needed and", etotal_int, "events are expected.")
    
    return(list(
      n = n,
      etotal = etotal_int,
      graf = graf,
      data = dat, 
      text = text
    ))
  }
#' @examples
#' samplesize_given_power(mods = mods, alpha = 0.025, ratio, des_pow = 0.8, 
#' end_rec = 1, end_stu = 3, model = 2, n_mind = 10)
```

```{r, fig.width = 6.9, out.width = '100%'}
final_result <- samplesize_given_power(mods, alpha = 0.025, ratio, des_pow = 0.8, end_rec = 1, 
         end_stu = 3, model = 2, n_mind = 10)
final_result$text
final_result$graf
```




